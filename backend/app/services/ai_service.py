"""AI food recognition service using Gemini Vision / GPT-4o / Agent Maestro."""

import base64
import io
import json
import logging

import httpx
from PIL import Image

from app.config import settings
from app.schemas.food import (
    AnalysisResponse,
    NutritionData,
    DetectedFoodResponse,
    BoundingBox,
)

logger = logging.getLogger(__name__)


def _resize_image(image_data: bytes, max_size: int = 512, quality: int = 70) -> bytes:
    """Resize and compress image to reduce token usage."""
    try:
        img = Image.open(io.BytesIO(image_data))

        # Convert to RGB if necessary
        if img.mode in ("RGBA", "P"):
            img = img.convert("RGB")

        # Resize if larger than max_size
        if max(img.size) > max_size:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

        # Save to bytes with compression
        buffer = io.BytesIO()
        img.save(buffer, format="JPEG", quality=quality, optimize=True)
        return buffer.getvalue()
    except Exception as e:
        logger.warning(f"Failed to resize image: {e}")
        return image_data

logger = logging.getLogger(__name__)

FOOD_ANALYSIS_PROMPT = """Analyze this food image and identify all food items visible.
For each food item, provide:
1. name (English)
2. name_zh (Chinese name)
3. emoji (a single emoji representing the food)
4. confidence (0.0 to 1.0)
5. bounding_box (approximate x, y, w, h as fractions of image dimensions, 0.0-1.0)
6. calories (estimated kcal for the visible portion)
7. protein_grams
8. carbs_grams
9. fat_grams
10. color (a unique hex color for each food item, use visually distinct colors)

Also provide:
- total_calories: sum of all food items
- total_nutrition: { protein_g, carbs_g, fat_g, fiber_g }
- ai_analysis: a brief nutritional analysis in Chinese (2-3 sentences)
- tags: relevant tags like ["high-protein", "low-carb", "balanced", "vegetarian", etc.]

Return ONLY valid JSON in this exact format:
{
  "detected_foods": [
    {
      "name": "Grilled Chicken",
      "name_zh": "çƒ¤é¸¡èƒ¸",
      "emoji": "ğŸ—",
      "confidence": 0.95,
      "bounding_box": {"x": 0.1, "y": 0.2, "w": 0.3, "h": 0.3},
      "calories": 250,
      "protein_grams": 30.0,
      "carbs_grams": 0.0,
      "fat_grams": 12.0,
      "color": "#FF6B6B"
    },
    {
      "name": "White Rice",
      "name_zh": "ç™½ç±³é¥­",
      "emoji": "ğŸš",
      "confidence": 0.90,
      "bounding_box": {"x": 0.5, "y": 0.3, "w": 0.3, "h": 0.3},
      "calories": 200,
      "protein_grams": 4.0,
      "carbs_grams": 45.0,
      "fat_grams": 0.5,
      "color": "#4ECDC4"
    }
  ],
  "total_calories": 450,
  "total_nutrition": {"protein_g": 34.0, "carbs_g": 45.0, "fat_g": 12.5, "fiber_g": 2.0},
  "ai_analysis": "è¿™é¡¿é¥­è›‹ç™½è´¨å«é‡ä¸°å¯Œ...",
  "tags": ["high-protein"]
}"""


def _get_mock_analysis() -> dict:
    """Return mock analysis data for development when API keys are not configured."""
    return {
        "detected_foods": [
            {
                "name": "Rice",
                "name_zh": "ç±³é¥­",
                "emoji": "ğŸš",
                "confidence": 0.92,
                "bounding_box": {"x": 0.1, "y": 0.3, "w": 0.35, "h": 0.35},
                "calories": 200,
                "protein_grams": 4.0,
                "carbs_grams": 45.0,
                "fat_grams": 0.5,
                "color": "#FFF8DC",
            },
            {
                "name": "Stir-fried Vegetables",
                "name_zh": "ç‚’æ—¶è”¬",
                "emoji": "ğŸ¥¦",
                "confidence": 0.88,
                "bounding_box": {"x": 0.5, "y": 0.2, "w": 0.4, "h": 0.3},
                "calories": 80,
                "protein_grams": 3.0,
                "carbs_grams": 8.0,
                "fat_grams": 5.0,
                "color": "#228B22",
            },
            {
                "name": "Braised Pork",
                "name_zh": "çº¢çƒ§è‚‰",
                "emoji": "ğŸ¥©",
                "confidence": 0.85,
                "bounding_box": {"x": 0.3, "y": 0.5, "w": 0.3, "h": 0.25},
                "calories": 320,
                "protein_grams": 22.0,
                "carbs_grams": 5.0,
                "fat_grams": 24.0,
                "color": "#8B4513",
            },
        ],
        "total_calories": 600,
        "total_nutrition": {
            "protein_g": 29.0,
            "carbs_g": 58.0,
            "fat_g": 29.5,
            "fiber_g": 4.0,
        },
        "ai_analysis": "è¿™é¡¿é¥­è¥å…»è¾ƒä¸ºå‡è¡¡ï¼ŒåŒ…å«ä¸»é£Ÿã€è”¬èœå’Œè›‹ç™½è´¨ã€‚çº¢çƒ§è‚‰çš„è„‚è‚ªå«é‡è¾ƒé«˜ï¼Œå»ºè®®é€‚é‡é£Ÿç”¨ã€‚è”¬èœæä¾›äº†è‰¯å¥½çš„è†³é£Ÿçº¤ç»´ã€‚",
        "tags": ["balanced", "chinese-cuisine", "home-cooked"],
    }


_FOOD_COLORS = [
    "#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4",
    "#FFEAA7", "#DDA0DD", "#98D8C8", "#F7DC6F",
    "#BB8FCE", "#85C1E9", "#F0B27A", "#82E0AA",
]


def _parse_ai_response(raw: dict) -> AnalysisResponse:
    """Parse raw AI response dict into structured AnalysisResponse."""
    detected_foods = []
    for i, food_data in enumerate(raw.get("detected_foods", [])):
        bb = food_data.get("bounding_box", {})
        color = food_data.get("color") or _FOOD_COLORS[i % len(_FOOD_COLORS)]
        detected_foods.append(
            DetectedFoodResponse(
                name=food_data.get("name", "Unknown"),
                name_zh=food_data.get("name_zh", "æœªçŸ¥"),
                emoji=food_data.get("emoji", "ğŸ½"),
                confidence=food_data.get("confidence", 0.5),
                bounding_box=BoundingBox(
                    x=bb.get("x", 0),
                    y=bb.get("y", 0),
                    w=bb.get("w", 0),
                    h=bb.get("h", 0),
                ),
                calories=food_data.get("calories", 0),
                protein_grams=food_data.get("protein_grams", 0),
                carbs_grams=food_data.get("carbs_grams", 0),
                fat_grams=food_data.get("fat_grams", 0),
                color=color,
            )
        )

    total_nutrition_raw = raw.get("total_nutrition", {})
    total_nutrition = NutritionData(
        protein_g=total_nutrition_raw.get("protein_g", 0),
        carbs_g=total_nutrition_raw.get("carbs_g", 0),
        fat_g=total_nutrition_raw.get("fat_g", 0),
        fiber_g=total_nutrition_raw.get("fiber_g", 0),
    )

    return AnalysisResponse(
        image_url="",
        total_calories=raw.get("total_calories", 0),
        total_nutrition=total_nutrition,
        detected_foods=detected_foods,
        ai_analysis=raw.get("ai_analysis", ""),
        tags=raw.get("tags", []),
    )


async def _analyze_with_gemini(image_data: bytes) -> dict | None:
    """Call Google Gemini Vision API to analyze food image.

    Returns:
        Parsed dict on success, None on failure
    """
    if not settings.gemini_api_key:
        logger.info("Gemini API Key æœªé…ç½®ï¼Œè·³è¿‡")
        return None

    try:
        b64_image = base64.b64encode(image_data).decode("utf-8")
        logger.info(f"Gemini: å›¾ç‰‡ base64 é•¿åº¦: {len(b64_image)} å­—ç¬¦")
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={settings.gemini_api_key[:8]}..."

        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": FOOD_ANALYSIS_PROMPT},
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": b64_image,
                            }
                        },
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "maxOutputTokens": 2048,
            },
        }

        real_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={settings.gemini_api_key}"
        async with httpx.AsyncClient(timeout=30.0) as client:
            logger.info("å‘é€è¯·æ±‚åˆ° Gemini Vision API...")
            response = await client.post(real_url, json=payload)
            logger.info(f"Gemini å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.status_code != 200:
                logger.error(f"Gemini é”™è¯¯å“åº”: {response.text[:1000]}")
            response.raise_for_status()
            result = response.json()

        # Extract text from Gemini response
        text = result["candidates"][0]["content"]["parts"][0]["text"]
        logger.info(f"Gemini åŸå§‹å“åº” (å®Œæ•´): {text}")
        # Clean up markdown code fences if present
        text = text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()

        parsed = json.loads(text)
        logger.info(f"Gemini JSON è§£ææˆåŠŸï¼ŒåŒ…å« {len(parsed.get('detected_foods', []))} ç§é£Ÿç‰©")
        return parsed

    except Exception as e:
        logger.error(f"Gemini API è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        logger.error(f"å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
        return None


async def _analyze_with_openai(image_data: bytes) -> dict | None:
    """Call OpenAI GPT-4o API to analyze food image (fallback).

    Returns:
        Parsed dict on success, None on failure
    """
    if not settings.openai_api_key:
        return None

    try:
        b64_image = base64.b64encode(image_data).decode("utf-8")
        url = "https://api.openai.com/v1/chat/completions"

        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": FOOD_ANALYSIS_PROMPT},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{b64_image}",
                                "detail": "high",
                            },
                        },
                    ],
                }
            ],
            "max_tokens": 2048,
            "temperature": 0.1,
        }

        headers = {
            "Authorization": f"Bearer {settings.openai_api_key}",
            "Content-Type": "application/json",
        }

        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()

        text = result["choices"][0]["message"]["content"]
        # Clean up markdown code fences if present
        text = text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()

        return json.loads(text)

    except Exception as e:
        logger.error(f"OpenAI API call failed: {e}")
        return None


async def _analyze_with_agent_maestro(image_data: bytes) -> dict | None:
    """Call Agent Maestro proxy (Gemini API) to analyze food image.

    Returns:
        Parsed dict on success, None on failure
    """
    if not settings.agent_maestro_enabled:
        logger.info("Agent Maestro æœªå¯ç”¨ (agent_maestro_enabled=False)")
        return None

    try:
        # Resize image to reduce token usage
        logger.info(f"å‹ç¼©å‰å›¾ç‰‡å¤§å°: {len(image_data)} bytes")
        resized_image = _resize_image(image_data, max_size=512, quality=70)
        logger.info(f"å‹ç¼©åå›¾ç‰‡å¤§å°: {len(resized_image)} bytes (max_size=512, quality=70)")

        # è®°å½•å‹ç¼©åçš„å›¾ç‰‡ä¿¡æ¯
        try:
            resized_img = Image.open(io.BytesIO(resized_image))
            logger.info(f"å‹ç¼©åå›¾ç‰‡å°ºå¯¸: {resized_img.size[0]}x{resized_img.size[1]}, æ¨¡å¼: {resized_img.mode}")
        except Exception:
            pass

        b64_image = base64.b64encode(resized_image).decode("utf-8")
        logger.info(f"Base64 ç¼–ç åé•¿åº¦: {len(b64_image)} å­—ç¬¦")

        url = f"{settings.agent_maestro_gemini_base_url}/v1beta/models/{settings.agent_maestro_gemini_model}:generateContent"

        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": FOOD_ANALYSIS_PROMPT},
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": b64_image,
                            }
                        },
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "maxOutputTokens": 2048,
            },
        }

        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": "agent-maestro",
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            logger.info(f"å‘é€è¯·æ±‚åˆ° Agent Maestro: {url}")
            logger.info(f"æ¨¡å‹: {settings.agent_maestro_gemini_model}")
            logger.info(f"Prompt é•¿åº¦: {len(FOOD_ANALYSIS_PROMPT)} å­—ç¬¦")
            response = await client.post(url, json=payload, headers=headers)
            logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.status_code != 200:
                logger.error(f"å“åº”å†…å®¹: {response.text[:1000]}")
            response.raise_for_status()
            result = response.json()

        # Extract and concatenate text from all parts (Gemini may split response into multiple parts)
        parts = result["candidates"][0]["content"]["parts"]
        logger.info(f"å“åº”åŒ…å« {len(parts)} ä¸ª parts")
        text = "".join(part.get("text", "") for part in parts)
        logger.info(f"AI åŸå§‹å“åº”æ–‡æœ¬ (å®Œæ•´): {text}")

        # Clean up markdown code fences if present
        text = text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()

        logger.info(f"æ¸…ç†å JSON æ–‡æœ¬: {text}")
        parsed = json.loads(text)
        logger.info(f"JSON è§£ææˆåŠŸï¼ŒåŒ…å« {len(parsed.get('detected_foods', []))} ç§é£Ÿç‰©")
        return parsed

    except json.JSONDecodeError as e:
        logger.error(f"Agent Maestro JSON è§£æå¤±è´¥: {e}")
        logger.error(f"æ— æ³•è§£æçš„æ–‡æœ¬: {text if 'text' in dir() else 'N/A'}")
        return None
    except Exception as e:
        logger.error(f"Agent Maestro (Gemini) API è°ƒç”¨å¤±è´¥: {e}")
        logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        logger.error(f"å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
        return None


async def _analyze_with_anthropic(image_data: bytes) -> dict | None:
    """Call Anthropic Claude API (via proxy) to analyze food image.

    Returns:
        Parsed dict on success, None on failure
    """
    if not settings.anthropic_enabled:
        logger.info("Anthropic Claude æœªå¯ç”¨")
        return None

    try:
        resized_image = _resize_image(image_data, max_size=512, quality=70)
        b64_image = base64.b64encode(resized_image).decode("utf-8")
        logger.info(f"Anthropic: å‹ç¼©åå›¾ç‰‡å¤§å°: {len(resized_image)} bytes, base64 é•¿åº¦: {len(b64_image)}")

        url = f"{settings.anthropic_base_url}/v1/messages"

        payload = {
            "model": settings.anthropic_model,
            "max_tokens": 2048,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": b64_image,
                            },
                        },
                        {
                            "type": "text",
                            "text": FOOD_ANALYSIS_PROMPT,
                        },
                    ],
                }
            ],
        }

        headers = {
            "Content-Type": "application/json",
            "x-api-key": "agent-maestro",
            "anthropic-version": "2023-06-01",
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            logger.info(f"å‘é€è¯·æ±‚åˆ° Anthropic Claude: {url}")
            logger.info(f"æ¨¡å‹: {settings.anthropic_model}")
            response = await client.post(url, json=payload, headers=headers)
            logger.info(f"Anthropic å“åº”çŠ¶æ€ç : {response.status_code}")
            if response.status_code != 200:
                logger.error(f"Anthropic é”™è¯¯å“åº”: {response.text[:1000]}")
            response.raise_for_status()
            result = response.json()

        # Extract text from Claude response
        text = ""
        for block in result.get("content", []):
            if block.get("type") == "text":
                text += block.get("text", "")

        logger.info(f"Anthropic åŸå§‹å“åº” (å®Œæ•´): {text}")

        # Clean up markdown code fences if present
        text = text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()

        parsed = json.loads(text)
        logger.info(f"Anthropic JSON è§£ææˆåŠŸï¼ŒåŒ…å« {len(parsed.get('detected_foods', []))} ç§é£Ÿç‰©")
        return parsed

    except json.JSONDecodeError as e:
        logger.error(f"Anthropic JSON è§£æå¤±è´¥: {e}")
        return None
    except Exception as e:
        logger.error(f"Anthropic Claude API è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        logger.error(f"å®Œæ•´å †æ ˆ: {traceback.format_exc()}")
        return None


async def analyze_food_image(image_data: bytes) -> AnalysisResponse:
    """Analyze a food image using cloud AI service.

    Strategy:
    1. Try Anthropic Claude (fastest, ~3.6s) - é¦–é€‰
    2. Try Agent Maestro proxy (Gemini) - å¤‡é€‰
    3. Try Gemini Vision API (direct)
    4. Fallback to GPT-4o
    5. Return mock data if none available
    """
    logger.info("========== å¼€å§‹é£Ÿç‰©å›¾ç‰‡åˆ†æ ==========")
    logger.info(f"æ”¶åˆ°å›¾ç‰‡æ•°æ®: {len(image_data)} bytes ({len(image_data)/1024:.1f} KB)")

    # è®°å½•å›¾ç‰‡åŸºæœ¬ä¿¡æ¯
    try:
        img = Image.open(io.BytesIO(image_data))
        logger.info(f"å›¾ç‰‡æ ¼å¼: {img.format}, æ¨¡å¼: {img.mode}, å°ºå¯¸: {img.size[0]}x{img.size[1]}")
    except Exception as e:
        logger.warning(f"æ— æ³•è§£æå›¾ç‰‡å…ƒæ•°æ®: {e}")

    # è®°å½•å¯ç”¨çš„ AI æœåŠ¡
    logger.info(f"Anthropic Claude å¯ç”¨: {settings.anthropic_enabled}")
    logger.info(f"Agent Maestro å¯ç”¨: {settings.agent_maestro_enabled}")
    logger.info(f"Gemini API Key å·²é…ç½®: {bool(settings.gemini_api_key)}")
    logger.info(f"OpenAI API Key å·²é…ç½®: {bool(settings.openai_api_key)}")

    # 1. Try Anthropic Claude first (æœ€å¿«)
    logger.info("--- å°è¯• Anthropic Claude ---")
    result = await _analyze_with_anthropic(image_data)
    if result is not None:
        logger.info("Anthropic Claude è¿”å›æˆåŠŸ")
    else:
        logger.info("Anthropic Claude æœªè¿”å›ç»“æœï¼Œå°è¯•ä¸‹ä¸€ä¸ª")

    # 2. Try Agent Maestro (Gemini proxy)
    if result is None:
        logger.info("--- å°è¯• Agent Maestro (Gemini) ---")
        result = await _analyze_with_agent_maestro(image_data)
        if result is not None:
            logger.info("Agent Maestro è¿”å›æˆåŠŸ")
        else:
            logger.info("Agent Maestro æœªè¿”å›ç»“æœï¼Œå°è¯•ä¸‹ä¸€ä¸ª")

    # 3. Try Gemini direct
    if result is None:
        logger.info("--- å°è¯• Gemini Vision API ---")
        result = await _analyze_with_gemini(image_data)
        if result is not None:
            logger.info("Gemini è¿”å›æˆåŠŸ")
        else:
            logger.info("Gemini æœªè¿”å›ç»“æœï¼Œå°è¯•ä¸‹ä¸€ä¸ª")

    # 4. Fallback to OpenAI
    if result is None:
        logger.info("--- å°è¯• OpenAI GPT-4o ---")
        result = await _analyze_with_openai(image_data)
        if result is not None:
            logger.info("OpenAI è¿”å›æˆåŠŸ")
        else:
            logger.info("OpenAI æœªè¿”å›ç»“æœ")

    # If no AI service available, use mock data
    if result is None:
        logger.warning("æ‰€æœ‰ AI æœåŠ¡å‡ä¸å¯ç”¨ï¼Œä½¿ç”¨ mock æ•°æ®ï¼")
        result = _get_mock_analysis()

    # æ‰“å°åŸå§‹ AI è¿”å›ç»“æœ
    logger.info(f"AI åŸå§‹ç»“æœ (detected_foods æ•°é‡): {len(result.get('detected_foods', []))}")
    for i, food in enumerate(result.get("detected_foods", [])):
        logger.info(
            f"  [{i}] {food.get('emoji','')} {food.get('name','')} ({food.get('name_zh','')}) "
            f"ç½®ä¿¡åº¦={food.get('confidence',0):.2f} "
            f"çƒ­é‡={food.get('calories',0)} kcal "
            f"bbox=({food.get('bounding_box',{}).get('x',0):.3f}, {food.get('bounding_box',{}).get('y',0):.3f}, "
            f"{food.get('bounding_box',{}).get('w',0):.3f}, {food.get('bounding_box',{}).get('h',0):.3f})"
        )
    logger.info(f"æ€»çƒ­é‡: {result.get('total_calories', 0)}")
    logger.info(f"AIåˆ†æ: {result.get('ai_analysis', '')}")
    logger.info(f"æ ‡ç­¾: {result.get('tags', [])}")

    parsed = _parse_ai_response(result)
    logger.info("========== é£Ÿç‰©åˆ†æå®Œæˆ ==========")
    return parsed
